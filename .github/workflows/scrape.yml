name: Scrape Events

on:
  schedule:
    # Run weekly on Sunday at 2 AM UTC (9 PM Saturday EST)
    - cron: '0 2 * * 0'
  workflow_dispatch:  # Allow manual triggering

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
      
      - name: Install Node.js dependencies
        run: npm install
      
      - name: Install Python dependencies
        run: pip install -r requirements.txt
      
      - name: Run data pipeline
        env:
          BROWSERBASE_API_KEY: ${{ secrets.BROWSERBASE_API_KEY }}
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: python3 src/run_pipeline.py
      
      - name: Upload pipeline report
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: pipeline-report-${{ github.run_id }}
          path: data/output/pipeline_report_*.json
          retention-days: 30
      
      - name: Upload scraper test reports
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: scraper-test-reports-${{ github.run_id }}
          path: data/output/scrape_test_report_*.json
          retention-days: 30

